# Environment settings
DEVELOPMENT_MODE=True
DEBUG=True
LOG_LEVEL=INFO

# API keys and credentials
OPENAI_API_KEY=your_openai_api_key_here
PINECONE_API_KEY=your_pinecone_api_key_here
PINECONE_INDEX_NAME=financial-qa-chatbot

# Google Cloud Firestore
GOOGLE_APPLICATION_CREDENTIALS=path/to/your/service_key.json
FIREBASE_SERVICE_ACCOUNT_JSON=your_firestore_service_account_json_here

# LLM Configuration
DEFAULT_MODEL=gpt-4
EMBEDDING_MODEL=text-embedding-ada-002

# Retrieval Configuration
TOP_K_RETRIEVAL=5

# Re-ranking Configuration
PRE_INIT_MODEL=False  # Set to True to pre-initialize the model at startup
PRE_WARM_CACHE=False  # Set to True to pre-warm the cache with common queries
RERANKING_MODEL=cross-encoder/ms-marco-MiniLM-L-6-v2
RERANKING_BATCH_SIZE=32
RERANKING_CACHE_SIZE=1000
USE_GPU=False  # Set to True to use GPU acceleration if available 